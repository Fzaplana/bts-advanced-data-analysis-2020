{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Advanced_Data_Analysis_Other_TF_APIs_NOTsolved.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GeRDnu2RaDJr",
        "I-OT0GYlbGc1",
        "PYVM2tN8cXXf"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB_ck5OSE3TU",
        "colab_type": "text"
      },
      "source": [
        "![BTS](https://github.com/vfp1/bts-mbds-data-science-foundations-2019/raw/master/sessions/img/Logo-BTS.jpg)\n",
        "\n",
        "# Session 05: Other TF APIs\n",
        "### Victor F. Pajuelo Madrigal <victor.pajuelo@bts.tech> - Advanced Data Analysis (23-04-2020)\n",
        "\n",
        "Open this notebook in Google Colaboratory: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vfp1/bts-advanced-data-analysis-2020/blob/master/S05_Other_TF_APIs/05_Advanced_Data_Analysis_Other_TF_APIs_NOTsolved.ipynb)\n",
        "\n",
        "**Resources (code patched and updated from):**\n",
        "* TensorFlow Authors\n",
        "* Aurelien Geron's O'Reilly's \"Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeRDnu2RaDJr",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGwo4GAGaDJt",
        "colab_type": "text"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaDdPQQiaDJu",
        "colab_type": "code",
        "outputId": "4a2d7bfa-bcf8-4118-d02e-af1965927107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !pip install -q -U tfx==0.21.2\n",
        "    print(\"You can safely ignore the package incompatibility errors.\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"data\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1MB 3.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 64.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 59.2MB 73kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9MB 59.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 57.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 49.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 68.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 54.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.4MB 49.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 43.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 41.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 57.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4MB 37.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7MB 42.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 66.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 59.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 67.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 13.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 68.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 66.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 65.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 57.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 69.4MB/s \n",
            "\u001b[?25h  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-transform (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for httplib2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.9 has requirement dill>=0.3.1, but you'll have dill 0.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-python-client 1.7.12 has requirement httplib2<1dev,>=0.17.0, but you'll have httplib2 0.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-serving-api 2.1.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 2.2.0rc3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-transform 0.21.2 has requirement tensorflow<2.2,>=1.15, but you'll have tensorflow 2.2.0rc3 which is incompatible.\u001b[0m\n",
            "You can safely ignore the package incompatibility errors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-OT0GYlbGc1",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "# TensorFlow as NumPy\n",
        "\n",
        "UUID - #S5C1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9lrS88taDJ1",
        "colab_type": "text"
      },
      "source": [
        "## Tensors and operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CudaFKiaDJ1",
        "colab_type": "text"
      },
      "source": [
        "### Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lEMC2LtcXJC",
        "colab_type": "text"
      },
      "source": [
        "You can create a tensor with `tf.constant()`. For example, here is a tensor representing a **matrix** with **two rows** and **three columns of floats**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pHBK9_RaDJ2",
        "colab_type": "code",
        "outputId": "18e64bf5-bef6-45d4-dd6e-3bf48b2c2b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS9F3WwEcp8L",
        "colab_type": "text"
      },
      "source": [
        "A tf.Tensor can also be a **scalar**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJIm4W3uaDJ8",
        "colab_type": "code",
        "outputId": "c42a298c-4f9f-40ff-8fc7-72fc807e268a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.constant(42) # scalar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgKKC5KLdNOq",
        "colab_type": "text"
      },
      "source": [
        "Just like if we will have an `ndarray`, a `tf.Tensor` has a shape and a data type (`dtype`) or the number of dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IZbdbM_aDKG",
        "colab_type": "code",
        "outputId": "a11ea137-8d3f-4490-915f-225e113e33d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRK_SMYWaDKL",
        "colab_type": "code",
        "outputId": "f0e73205-f950-4064-8a51-14383893dc60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-_b8QybaDKR",
        "colab_type": "code",
        "outputId": "45b25cd6-a257-4b2d-fd92-f187ac8e5d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd2WvuOZggG4",
        "colab_type": "code",
        "outputId": "90126191-5327-4752-d05a-0f299e92aff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.ndim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCLWCVPQaDKX",
        "colab_type": "text"
      },
      "source": [
        "### Indexing\n",
        "\n",
        "Indexing works in a similar way to NumPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTXVTbqhaDKX",
        "colab_type": "code",
        "outputId": "7c59701e-568c-4049-deb1-6f83872dbbc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Get all the rows from column 1 to the end (remember that indexing starts at 0)\n",
        "t[:, 1:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[2., 3.],\n",
              "       [5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apeW2izJaDKc",
        "colab_type": "code",
        "outputId": "2b6a6976-f3f4-44e4-b21b-b9b44629d8ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        "Using ellipsis to expand the number of : objects needed to\n",
        "make a selection tuple of the same lenght as t.ndim. Remember, \n",
        "only one ellipsis can be present in indexing\n",
        "\"\"\"\n",
        "t[..., 1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 5.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93n43R5uhLsu",
        "colab_type": "code",
        "outputId": "52741c30-d10a-45fe-d056-574303703483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "\"\"\"\n",
        "Using an ellipsis with tf.newaxis. \n",
        "This serves to expand the dimensions of the resulting selection by one unit-length dimension. \n",
        "The added dimension is the position of the newaxis object in the selection tuple.\n",
        "\"\"\"\n",
        "t[..., 1, tf.newaxis]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[2.],\n",
              "       [5.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvpuhS2phbhD",
        "colab_type": "code",
        "outputId": "0eb7e251-3bf7-44d6-b833-db1c32712884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t[tf.newaxis, ..., 1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[2., 5.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzqs3cx6aDKh",
        "colab_type": "text"
      },
      "source": [
        "### Ops (operations)\n",
        "\n",
        "All sort of tensor (multidimensional arrays) are possible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHkDLx3riOTn",
        "colab_type": "text"
      },
      "source": [
        "`t + 10` is equivalent to calling `tf.add(t, 10)` (indeed, Python calls the magic method `t.__add__(10)`, which just calls tf.add(t, 10))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KICP8iN2aDKi",
        "colab_type": "code",
        "outputId": "85a6dcfd-075e-4363-a3fa-65103b753629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "t + 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[11., 12., 13.],\n",
              "       [14., 15., 16.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcbrhAMFiYP1",
        "colab_type": "code",
        "outputId": "63577e51-a0b4-4d00-c693-0c31a345efe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tf.add(t, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[11., 12., 13.],\n",
              "       [14., 15., 16.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msoSGV38iepM",
        "colab_type": "text"
      },
      "source": [
        "Other operators like - and * are also supported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSbYYvjxihjW",
        "colab_type": "code",
        "outputId": "c99d93ae-0e2e-4599-b7b8-756f0f4128c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "t - 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[-9., -8., -7.],\n",
              "       [-6., -5., -4.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6FDfd2Yis-l",
        "colab_type": "code",
        "outputId": "18c392cd-5875-4646-8df3-97d0d17ed197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "t * 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[10., 20., 30.],\n",
              "       [40., 50., 60.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfWq_ZXci3dT",
        "colab_type": "text"
      },
      "source": [
        "You can also use square functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7xUiT2GaDKn",
        "colab_type": "code",
        "outputId": "0470c2e0-d1d2-4c4b-c4ca-8d14a4ac62ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tf.square(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[ 1.,  4.,  9.],\n",
              "       [16., 25., 36.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOTbCQFGi8SE",
        "colab_type": "text"
      },
      "source": [
        "The @ operator was added in Python 3.5, for matrix multiplication: it is equivalent to calling the tf.matmul() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I1Ce5FUaDKr",
        "colab_type": "code",
        "outputId": "4feec3b4-f806-4815-af6d-7681d5b88c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "t @ tf.transpose(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[14., 32.],\n",
              "       [32., 77.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH-MSjZ5jIpc",
        "colab_type": "code",
        "outputId": "91f4e81b-b3d2-421b-b41f-1a81ec53e648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tf.matmul(t, tf.transpose(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[14., 32.],\n",
              "       [32., 77.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhOmtxjqjh5-",
        "colab_type": "text"
      },
      "source": [
        "#### Other operations\n",
        "\n",
        "You will find **all the basic math operations you need** (`tf.add()`, `tf.multiply()`, `tf.square()`, `tf.exp()`, `tf.sqrt()`, etc.) and most operations that you can find in NumPy (e.g., `tf.reshape()`, `tf.squeeze()`, `tf.tile()`). \n",
        "\n",
        "Some functions **have a different name than in NumPy**; for instance, `tf.reduce_mean()`, `tf.reduce_sum()`, `tf.reduce_max()`, and `tf.math.log()` are the equivalent of `np.mean()`, `np.sum()`, `np.max()` and `np.log()`. \n",
        "\n",
        "**When the name differs, there is often a good reason for it.** For example, in TensorFlow you must write `tf.transpose(t)`; you cannot just write `t.T` like in NumPy. \n",
        "\n",
        "The reason is that **the `tf.transpose()` function does not do exactly the same thing as NumPy’s `T` attribute**: \n",
        "\n",
        " * In TensorFlow, a new tensor is created with its own copy of the transposed data\n",
        " * In NumPy, `t.T` is just a transposed view on the same data. \n",
        " \n",
        "Similarly, **the `tf.reduce_sum()` operation is named this way because its GPU kernel (i.e., GPU implementation) uses a *reduce algorithm* that does not guarantee the order in which the elements are added**: because 32-bit floats have limited precision, the result may change ever so slightly every time you call this operation. \n",
        "\n",
        "The same is true of `tf.reduce_mean()` (but of course tf.reduce_max() is deterministic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGkSy1RRaDK3",
        "colab_type": "text"
      },
      "source": [
        "### From/To NumPy\n",
        "\n",
        "You can create a tensor from a NumPy array and you can create a NumPy array from a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXpqLZrmaDK3",
        "colab_type": "code",
        "outputId": "a69ee39a-0609-4a05-ae59-d1e704dd0c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Turn a NumPy array into a tensor\n",
        "a = np.array([2., 4., 5.])\n",
        "tf.constant(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evha8o-BaDK7",
        "colab_type": "code",
        "outputId": "e7728321-26da-493f-aba2-8ccc3e0d2116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Turn a tensor to NumPy array\n",
        "t.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epETDGaoaDLC",
        "colab_type": "code",
        "outputId": "28b5e96e-c1d0-4b05-9622-d1c1bab03dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Turn a tensor to NumPy array\n",
        "np.array(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3JUEHv0JT14",
        "colab_type": "text"
      },
      "source": [
        "You can even apply TensorFlow operations to NumPy arrays and NumPy operations to tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMrFBY2saDLG",
        "colab_type": "code",
        "outputId": "4d7089c3-1ac4-4fbb-96ec-2301a5352cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Apply TensorFlow square operation to NumPy array\n",
        "# Returns a tensor\n",
        "tf.square(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h0wTQMqaDLO",
        "colab_type": "code",
        "outputId": "08652057-02d4-4d35-8832-a372f3072776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Apply NumPy square operation to a tensor\n",
        "# Returns an array\n",
        "np.square(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  4.,  9.],\n",
              "       [16., 25., 36.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XItWDUDcLBdK",
        "colab_type": "text"
      },
      "source": [
        "**WARNING!!!** NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit.\n",
        "\n",
        "This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when you create a tensor from a NumPy array, make sure to set `dtype=tf.float32`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "719DzHNLLe7b",
        "colab_type": "code",
        "outputId": "a2665ef8-27a0-4ec6-c2ff-ae701d536874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "b = tf.constant(a, dtype=tf.float32)\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 4., 5.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxsTQgLXL1q_",
        "colab_type": "code",
        "outputId": "992615c4-d3df-4f09-d20d-b4f4ba5a58e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.square(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 4., 16., 25.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lvkBqpyaDLU",
        "colab_type": "text"
      },
      "source": [
        "### Type Conversions\n",
        "\n",
        "This can be a nightmare at first, but it becomes extremely useful. Just be patient.\n",
        "\n",
        "**Type conversions can significantly hurt performance**, and they can easily go unnoticed when they are done automatically. To avoid this, **TensorFlow does not perform any type conversions automatically**: \n",
        "* TensorFlow just *raises an exception if you try to execute an operation on tensors with incompatible types*. \n",
        "* You cannot add a float tensor and an integer tensor, and you cannot even add a 32-bit float and a 64-bit float"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CnW7UD0Pezj",
        "colab_type": "code",
        "outputId": "663d9535-d939-4139-d5ed-c21b29d7131e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "tf.constant(2.0) + tf.constant(40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-0e485bc98398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLm8944YaDLV",
        "colab_type": "code",
        "outputId": "1b74b872-5531-45e2-84b6-a03efdda6f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "try:\n",
        "    tf.constant(2.0) + tf.constant(40)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxAaAUljaDLY",
        "colab_type": "code",
        "outputId": "244aeeb0-8944-48b8-e75e-3074cae8d145",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: add/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps2wc_CJPyQf",
        "colab_type": "text"
      },
      "source": [
        "This can be very, very, very annoying at first. But this is done for a good reason. \n",
        "\n",
        "And you can always use tf.cast() if you really need to convert types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grA6rnlWaDLc",
        "colab_type": "code",
        "outputId": "dec2946e-7498-4c3d-c2ee-6b5d6979fa6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t2 = tf.constant(40., dtype=tf.float64)\n",
        "tf.constant(2.0) + tf.cast(t2, tf.float32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArCw-zKHQBA9",
        "colab_type": "code",
        "outputId": "e2d18b50-d11d-4371-8890-f3173b5fea92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t3 = tf.cast(t2, tf.int32)\n",
        "tf.constant(2.0) + tf.cast(t3, tf.float32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HOCOhnVAQjHh"
      },
      "source": [
        "### Variables\n",
        "\n",
        "The `tf.Tensor` values we’ve seen so far **are immutable**: you cannot modify them. \n",
        "\n",
        "This means that **we cannot use regular tensors to implement weights in a neural network, since they need to be tweaked by backpropagation**.\n",
        "\n",
        "Plus, other parameters may also need to change over time (e.g., a momentum optimizer keeps track of past gradients). What we need is a `tf.Variable`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lYFwaMJ1QjHi",
        "outputId": "482d81d5-9df6-4c29-b6ae-4de1664b2c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "v"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_ENkMToRXwl",
        "colab_type": "text"
      },
      "source": [
        "**A `tf.Variable` acts much like a `tf.Tensor`**: \n",
        "\n",
        "* You can perform the same operations with it\n",
        "* It plays nicely with NumPy as well\n",
        "* It is just as picky with data types. \n",
        "\n",
        "However, you can modify a `tf.Variable` while not with a `tf.Tensor`:\n",
        "\n",
        "* For instance, a `tf.Variable` can be modified in place using the `assign()` method (or `assign_add()` or `assign_sub()`, which increment or decrement the variable by the given value).\n",
        "* You can also **modify individual cells** (or slices), by using the cell’s (or slice’s) `assign()` method (direct item assignment will not work) or by using the `scatter_nd_update()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d16d44c3-320f-4853-f837-9da0af3aa790",
        "id": "0Th7t-LXQjHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Assign a value of 2*v to itself\n",
        "# => [[2., 4., 6.], [8., 10., 12.]]\n",
        "v.assign(2 * v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ba4cffa5-d4e7-4fee-c71c-38b63a33647a",
        "id": "5SM-fmf-QjHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Assign a value of 4 to v location 0,1\n",
        "# => [[2., 42., 6.], [8., 10., 12.]]\n",
        "v[0, 1].assign(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2., 42.,  6.],\n",
              "       [ 8., 10., 12.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "59a2bd40-fbcf-4934-e119-bcff38c13176",
        "id": "b8X8Ru8pQjHy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Asign 0,1 to the last column\n",
        "# => [[2., 42., 0.], [8., 10., 1.]]\n",
        "v[:, 2].assign([0., 1.])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[ 2., 42.,  0.],\n",
              "       [ 8., 10.,  1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMaUE-7wV9x2",
        "colab_type": "text"
      },
      "source": [
        "Direct item assignement will never work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85NciKviWCes",
        "colab_type": "code",
        "outputId": "d74d2a46-7506-463d-abb7-231a90980991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "v[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 8., 10.,  1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7f0de562-b4e0-45f6-d52c-877261d16717",
        "id": "T1V__PjSQjH3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "    v[1] = [7., 8., 9.]\n",
        "except TypeError as ex:\n",
        "    print(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'ResourceVariable' object does not support item assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b8121b03-5325-455f-f8f8-2317bde17ed2",
        "id": "MQ1CN_iIQjH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Update given index location with update values\n",
        "# => [[100., 42., 0.], [8., 10., 200.]]\n",
        "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
        "                    updates=[100., 200.])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
              "array([[100.,  42.,   0.],\n",
              "       [  8.,  10., 200.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb2WsFFZX1ju",
        "colab_type": "text"
      },
      "source": [
        "Understanding `assign`, `assign_add`, `assign_sub`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUL8nQJYXAqe",
        "colab_type": "code",
        "outputId": "75027fb1-a63d-4642-85ed-8b635b11e239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "v2 = tf.Variable(1.)\n",
        "v2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKjamMoDX_oq",
        "colab_type": "code",
        "outputId": "90f901da-d563-4daf-8aae-a87d6466210f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "v2.assign(4.) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=4.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MltRZk5EYDwr",
        "colab_type": "code",
        "outputId": "b7f215c5-a136-4235-a738-77cc92ad9cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "v2.assign_add(1.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=5.5>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mga6LDPQYHLh",
        "colab_type": "code",
        "outputId": "002d7c1a-9e47-49eb-dfa6-8725cc321775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "v2.assign_sub(1.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=4.0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IabktIWXYeIL",
        "colab_type": "text"
      },
      "source": [
        "**WARNING !!** In practice you will rarely have to create variables manually, since model parameters will generally be updated directly by the optimizers, so you will rarely need to update variables manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udez7UbUaDOl",
        "colab_type": "text"
      },
      "source": [
        "### Tensor Arrays\n",
        "\n",
        "Are lists of tensors. They have a fixed size by default but can optionally be made dynamic. All tensors they contain must have the same shape and data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5oR4KuDaDOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an array of Tensors\n",
        "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
        "array = array.write(0, tf.constant([1., 2.]))\n",
        "array = array.write(1, tf.constant([3., 10.]))\n",
        "array = array.write(2, tf.constant([5., 7.]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y7y2kBNZvRc",
        "colab_type": "text"
      },
      "source": [
        "Stacking the lists of tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL_pqpGwaDOy",
        "colab_type": "code",
        "outputId": "29b9f8e6-7a2a-46a4-939c-dc3b0f1baa60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "array.stack()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[ 1.,  2.],\n",
              "       [ 3., 10.],\n",
              "       [ 5.,  7.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19WY2cQCT5U7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# The Data API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYVM2tN8cXXf",
        "colab_type": "text"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "UUID - #S5C2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-rOALFlcXXg",
        "colab_type": "code",
        "outputId": "8132550f-03d7-4f4f-9cfa-e7945610d1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X = tf.range(10) #This could be any data tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QESz8_KcXXp",
        "colab_type": "text"
      },
      "source": [
        "Equivalently:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9sEyIBNcXXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-W4bgiVcXXu",
        "colab_type": "code",
        "outputId": "1a75c2a7-653f-45bd-e36d-ba386d4e14d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OPMZWzQiKjm",
        "colab_type": "text"
      },
      "source": [
        "## Chaining transformations\n",
        "\n",
        "UUID - #S5C3\n",
        "\n",
        "Repeat the dataset three times and split it in batches of 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "raises-exception"
        ],
        "id": "uKtYuGIrcXXz",
        "colab_type": "code",
        "outputId": "fdce559a-ce91-41eb-8391-fc598d832d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "dataset = dataset.repeat(3).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLkQ3ZdfhCPI",
        "colab_type": "text"
      },
      "source": [
        "Repeat the dataset three times and split it in batches of 10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKbzoTnAglzh",
        "colab_type": "code",
        "outputId": "f40536e4-7d10-436a-b904-a668fea66a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "dataset2 = tf.data.Dataset.range(10)\n",
        "dataset2 = dataset2.repeat(3).batch(10)\n",
        "for item in dataset2:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int64)\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int64)\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbSDlCUsh-Nw",
        "colab_type": "text"
      },
      "source": [
        "Use drop_remainder=True to have the batches with all the same size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SvE0nxEiHE-",
        "colab_type": "code",
        "outputId": "a1d09a31-5b82-4510-9d00-fa6630b5c125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "dataset3 = tf.data.Dataset.range(10)\n",
        "dataset3 = dataset3.repeat(3).batch(7, drop_remainder=True)\n",
        "for item in dataset3:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzJTq0lTkmR0",
        "colab_type": "text"
      },
      "source": [
        "Use the **`map()`** method to transform the items in a dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lckZz0jcXX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.map(lambda x: x * 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L29jq68cXX_",
        "colab_type": "code",
        "outputId": "5fba1543-5573-421c-926d-ae47def9d85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int64)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int64)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Ol6VgeoMf9",
        "colab_type": "text"
      },
      "source": [
        "Use the **`map()`** method with **`num_parallel_calls`**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysJZDWEfocyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset4 = dataset.map(lambda x: x * 2, num_parallel_calls=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41hK1KGuojZW",
        "colab_type": "code",
        "outputId": "64485b51-5324-425f-f1e2-d01d1fdb88f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "for item in dataset4:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  4  8 12 16 20 24], shape=(7,), dtype=int64)\n",
            "tf.Tensor([28 32 36  0  4  8 12], shape=(7,), dtype=int64)\n",
            "tf.Tensor([16 20 24 28 32 36  0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([ 4  8 12 16 20 24 28], shape=(7,), dtype=int64)\n",
            "tf.Tensor([32 36], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THAwsqJfpiEb",
        "colab_type": "text"
      },
      "source": [
        "Using **apply()** method to apply a transformation to the whole dataset instead item to item"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-V7kH0wcXYE",
        "colab_type": "code",
        "outputId": "e63f8642-f161-4055-b6d4-26e329493b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Create dataset with range\n",
        "dataset5 = tf.data.Dataset.range(100) \n",
        "\n",
        "# Function to create a filter\n",
        "def dataset_fn(ds): \n",
        "  return ds.filter(lambda x: x < 5) \n",
        "\n",
        "# Apply the function\n",
        "dataset5 = dataset5.apply(dataset_fn) \n",
        "\n",
        "# Print items filtered within dataset\n",
        "list(dataset5.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZW-zc1Dr3nA",
        "colab_type": "text"
      },
      "source": [
        "Using **`unbatch()`** to get the original dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbV3jPzwprrw",
        "colab_type": "code",
        "outputId": "044430d2-7a83-41a9-e5fa-9595c35b5357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "# Create dataset with range\n",
        "dataset6 = tf.data.Dataset.range(10) \n",
        "\n",
        "# Apply the repeat and batch\n",
        "dataset6 = dataset6.repeat(3).batch(7, drop_remainder=True)\n",
        "\n",
        "# Apply the unbatch\n",
        "dataset6 = dataset6.unbatch() \n",
        "\n",
        "# Print items filtered within dataset\n",
        "list(dataset6.as_numpy_iterator()) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO9Sg7Wqs4-S",
        "colab_type": "text"
      },
      "source": [
        "The **`filter()`** method also allows us to filter elements in an unbatched dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWLKsX6CcXYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataset with range\n",
        "dataset7 = tf.data.Dataset.range(10) \n",
        "\n",
        "# Apply the repeat and batch\n",
        "dataset7 = dataset7.repeat(3).batch(7, drop_remainder=True)\n",
        "\n",
        "# Apply an unbatch function\n",
        "dataset7 = dataset7.unbatch()\n",
        "\n",
        "# Apply a filter\n",
        "dataset7 = dataset7.filter(lambda x: x < 10)  # keep only items < 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1MX_P7WcXYT",
        "colab_type": "code",
        "outputId": "a4f645bb-d12a-41af-8aa9-67c4f3f58a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for item in dataset7.take(3):\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEKKZ8PAwYQB",
        "colab_type": "text"
      },
      "source": [
        "## Shuffling the data\n",
        "\n",
        "UUID - #S5C4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD3lWZ4tcXYn",
        "colab_type": "code",
        "outputId": "6fdf3597-881a-4b53-dbc4-06d222ce1699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "dataset = tf.data.Dataset.range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=3, seed=42).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1 3 0 4 2 5 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 7 1 0 3 2 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 6 9 8 9 7 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([3 1 4 5 2 8 7], shape=(7,), dtype=int64)\n",
            "tf.Tensor([6 9], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBVLvK1308hI",
        "colab_type": "code",
        "outputId": "fc1abb41-aacc-41fd-c3c9-b6ae4aebcd2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "dataset = tf.data.Dataset.range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=3, seed=42, reshuffle_each_iteration=True).batch(7).repeat(4)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1 3 0 4 2 5 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 7 1 0 3 2 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 6 9 8 9 7 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([3 1 4 5 2 8 7], shape=(7,), dtype=int64)\n",
            "tf.Tensor([6 9], shape=(2,), dtype=int64)\n",
            "tf.Tensor([1 3 0 2 6 7 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 9 4 0 2 1 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 6 7 8 9 1 2], shape=(7,), dtype=int64)\n",
            "tf.Tensor([0 5 4 6 3 5 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([7 8], shape=(2,), dtype=int64)\n",
            "tf.Tensor([0 1 3 4 5 6 7], shape=(7,), dtype=int64)\n",
            "tf.Tensor([2 8 1 2 0 9 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([6 5 7 4 0 9 2], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 3 5 8 4 7 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 6], shape=(2,), dtype=int64)\n",
            "tf.Tensor([2 3 1 0 5 6 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([7 9 0 4 3 4 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 2 8 7 6 9 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([2 1 4 5 3 7 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 8], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTLiNLQ_0Uwq",
        "colab_type": "code",
        "outputId": "218e97b4-4234-4cb9-bd4c-d5cca6538ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "dataset = tf.data.Dataset.range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=3, seed=42, reshuffle_each_iteration=False).batch(7).repeat(4)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 2 3 5 6 4 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 0 1 1 7 3 2], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 5 7 8 9 0 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 2 4 6 7 3 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 5], shape=(2,), dtype=int64)\n",
            "tf.Tensor([0 2 3 5 6 4 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 0 1 1 7 3 2], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 5 7 8 9 0 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 2 4 6 7 3 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 5], shape=(2,), dtype=int64)\n",
            "tf.Tensor([0 2 3 5 6 4 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 0 1 1 7 3 2], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 5 7 8 9 0 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 2 4 6 7 3 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 5], shape=(2,), dtype=int64)\n",
            "tf.Tensor([0 2 3 5 6 4 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 0 1 1 7 3 2], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 5 7 8 9 0 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 2 4 6 7 3 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 5], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCrv6FhAcXYx",
        "colab_type": "text"
      },
      "source": [
        "# Split the California dataset to multiple CSV files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suW2aWYb4x-6",
        "colab_type": "text"
      },
      "source": [
        "## Fetching input\n",
        "\n",
        "UUID - #S5C5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1KERwPgcXYy",
        "colab_type": "text"
      },
      "source": [
        "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc4OFCeJcXYz",
        "colab_type": "code",
        "outputId": "3529b14d-4aae-482e-bb5f-aafb0569d8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_mean = scaler.mean_\n",
        "X_std = scaler.scale_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqWhhbJncXY2",
        "colab_type": "text"
      },
      "source": [
        "For a very large dataset that does not fit in memory, you will typically want to split it into many files first, then have TensorFlow read these files in parallel. To demonstrate this, let's start by splitting the housing dataset and save it to 20 CSV files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ekz31sZcXY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "\n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y52_t9tCcXY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NumPy c_ == Translates slice objects to concatenation along the second axis.\n",
        "train_data = np.c_[X_train, y_train]\n",
        "valid_data = np.c_[X_valid, y_valid]\n",
        "test_data = np.c_[X_test, y_test]\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)\n",
        "\n",
        "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
        "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
        "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5FU-HTgcXZF",
        "colab_type": "text"
      },
      "source": [
        "Okay, now let's take a peek at the first few lines of one of these CSV files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbhFfr7HcXZP",
        "colab_type": "code",
        "outputId": "809dbd95-7812-485c-cf97-7df1142750fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "with open(train_filepaths[0]) as f:\n",
        "    for i in range(5):\n",
        "        print(f.readline(), end=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
            "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
            "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
            "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
            "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-BFC3jVcXZV",
        "colab_type": "code",
        "outputId": "6f9881a3-2aad-4e41-9864-d82e1827f0ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "train_filepaths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/housing/my_train_00.csv',\n",
              " 'datasets/housing/my_train_01.csv',\n",
              " 'datasets/housing/my_train_02.csv',\n",
              " 'datasets/housing/my_train_03.csv',\n",
              " 'datasets/housing/my_train_04.csv',\n",
              " 'datasets/housing/my_train_05.csv',\n",
              " 'datasets/housing/my_train_06.csv',\n",
              " 'datasets/housing/my_train_07.csv',\n",
              " 'datasets/housing/my_train_08.csv',\n",
              " 'datasets/housing/my_train_09.csv',\n",
              " 'datasets/housing/my_train_10.csv',\n",
              " 'datasets/housing/my_train_11.csv',\n",
              " 'datasets/housing/my_train_12.csv',\n",
              " 'datasets/housing/my_train_13.csv',\n",
              " 'datasets/housing/my_train_14.csv',\n",
              " 'datasets/housing/my_train_15.csv',\n",
              " 'datasets/housing/my_train_16.csv',\n",
              " 'datasets/housing/my_train_17.csv',\n",
              " 'datasets/housing/my_train_18.csv',\n",
              " 'datasets/housing/my_train_19.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Fvmoww91V7",
        "colab_type": "code",
        "outputId": "fad6f385-5193-4734-a70f-f672c349ea3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "valid_filepaths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/housing/my_valid_00.csv',\n",
              " 'datasets/housing/my_valid_01.csv',\n",
              " 'datasets/housing/my_valid_02.csv',\n",
              " 'datasets/housing/my_valid_03.csv',\n",
              " 'datasets/housing/my_valid_04.csv',\n",
              " 'datasets/housing/my_valid_05.csv',\n",
              " 'datasets/housing/my_valid_06.csv',\n",
              " 'datasets/housing/my_valid_07.csv',\n",
              " 'datasets/housing/my_valid_08.csv',\n",
              " 'datasets/housing/my_valid_09.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGrqoiLg95Dd",
        "colab_type": "code",
        "outputId": "d0ba9906-e7f7-47bc-f0a3-9da6efc54d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "test_filepaths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/housing/my_test_00.csv',\n",
              " 'datasets/housing/my_test_01.csv',\n",
              " 'datasets/housing/my_test_02.csv',\n",
              " 'datasets/housing/my_test_03.csv',\n",
              " 'datasets/housing/my_test_04.csv',\n",
              " 'datasets/housing/my_test_05.csv',\n",
              " 'datasets/housing/my_test_06.csv',\n",
              " 'datasets/housing/my_test_07.csv',\n",
              " 'datasets/housing/my_test_08.csv',\n",
              " 'datasets/housing/my_test_09.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2toWzH5zcXZZ",
        "colab_type": "text"
      },
      "source": [
        "## Building an Input Pipeline\n",
        "\n",
        "UUID - #S5C6\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gvH_nOVcXZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kfieq70cXZe",
        "colab_type": "code",
        "outputId": "b0854268-2c6b-488d-bee8-6f9b56e0bf31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "for filepath in filepath_dataset:\n",
        "    print(filepath)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'datasets/housing/my_train_15.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_08.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_03.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_01.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_10.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_05.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_19.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_16.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_02.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_09.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_00.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_07.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_12.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_04.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_17.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_11.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_14.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_18.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_06.csv', shape=(), dtype=string)\n",
            "tf.Tensor(b'datasets/housing/my_train_13.csv', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0L_65u5_4NN",
        "colab_type": "text"
      },
      "source": [
        "Using the **`interleave()`** method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Bgwvc1cXZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_readers = 5\n",
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "    cycle_length=n_readers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEYIsqLNcXZk",
        "colab_type": "code",
        "outputId": "aa091f12-241a-48a1-9f3c-fc5d9a8cbd9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "for line in dataset.take(5):\n",
        "    print(line.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'4.6477,38.0,5.03728813559322,0.911864406779661,745.0,2.5254237288135593,32.64,-117.07,1.504'\n",
            "b'8.72,44.0,6.163179916317992,1.0460251046025104,668.0,2.794979079497908,34.2,-118.18,4.159'\n",
            "b'3.8456,35.0,5.461346633416459,0.9576059850374065,1154.0,2.8778054862842892,37.96,-122.05,1.598'\n",
            "b'3.3456,37.0,4.514084507042254,0.9084507042253521,458.0,3.2253521126760565,36.67,-121.7,2.526'\n",
            "b'3.6875,44.0,4.524475524475524,0.993006993006993,457.0,3.195804195804196,34.04,-118.15,1.625'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZVsulcbIKix",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Inputs\n",
        "\n",
        "UUID - #S5C7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcuKFSGBcXZo",
        "colab_type": "text"
      },
      "source": [
        "What is a byte string? Let's check that with the code below. Notice that field 4 is interpreted as a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYEVgeWrcXZp",
        "colab_type": "code",
        "outputId": "75c88ee4-9022-436e-f596-92ec5c60729f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# We create a list of types of data\n",
        "record_defaults=[0, np.nan, tf.constant(np.nan, dtype=tf.float64), \"Hello\", tf.constant([])]\n",
        "\n",
        "# We parse the fields (we create a fake file '1,2,3,4,5') with record defaults\n",
        "parsed_fields = tf.io.decode_csv('1,2,3,4,5', record_defaults)\n",
        "\n",
        "# Notice that all the Tensors have a number, but the 4 has a b in front. \n",
        "# It is because \"Hello\" is a string\n",
        "parsed_fields"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=2.0>,\n",
              " <tf.Tensor: shape=(), dtype=float64, numpy=3.0>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFffVEcycXZy",
        "colab_type": "text"
      },
      "source": [
        "Notice that all missing fields are replaced with their default value, when provided:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQX2ObULcXZ0",
        "colab_type": "code",
        "outputId": "002f8cff-ac81-4755-d1e6-49d8403ad94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "parsed_fields = tf.io.decode_csv(',,,,5', record_defaults)\n",
        "parsed_fields"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=nan>,\n",
              " <tf.Tensor: shape=(), dtype=float64, numpy=nan>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'Hello'>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA8UhCHicXZ4",
        "colab_type": "text"
      },
      "source": [
        "The 5th field is compulsory (since we provided `tf.constant([])` as the \"default value\"), so we get an exception if we do not provide it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N-Ock0bcXZ4",
        "colab_type": "code",
        "outputId": "54ec3629-7124-48fa-98da-7c53b3e2f5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "    parsed_fields = tf.io.decode_csv(',,,,', record_defaults)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Field 4 is required but missing in record 0! [Op:DecodeCSV]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JteVTkgLcXZ-",
        "colab_type": "text"
      },
      "source": [
        "The number of fields should match exactly the number of fields in the `record_defaults`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1QNM3z-cXaA",
        "colab_type": "code",
        "outputId": "22c62bd4-730e-45d3-ed7f-121b494b836c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "    parsed_fields = tf.io.decode_csv('1,2,3,4,5,6,7', record_defaults)\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expect 5 fields but have 7 in record 0 [Op:DecodeCSV]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiVQbRv4MUll",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing function\n",
        "\n",
        "UUID - #S5C8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atnUHOz1cXaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_inputs = 8 # X_train.shape[-1]\n",
        "\n",
        "@tf.function\n",
        "def preprocess(line):\n",
        "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    x = tf.stack(fields[:-1])\n",
        "    y = tf.stack(fields[-1:])\n",
        "    return (x - X_mean) / X_std, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "686_Y4AacXaI",
        "colab_type": "code",
        "outputId": "99ee8240-e292-4d6e-f4fa-26e06f3db810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 0.16579157,  1.216324  , -0.05204565, -0.39215982, -0.5277444 ,\n",
              "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbE4g-9OUg-1",
        "colab_type": "text"
      },
      "source": [
        "## EXERCISES IN CLASS: Building an entire ETL function in TF\n",
        "\n",
        "UUID - #S5E1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-2Tn30rV-Gh",
        "colab_type": "text"
      },
      "source": [
        "Let's try to build an entire pipeline ourselves! How it will look like?\n",
        "\n",
        "1. List the filepaths and repeat if necessary\n",
        "2. Interleave the filepaths\n",
        "3. Shuffling the data with certain buffer size\n",
        "4. Call a preprocessing function (perhaps the one that we just build?) and use map() to transform the dataset accordingly\n",
        "5. Create and return a batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o94cSu6ecXaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV427XA4cXaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N_QI0xyb0u4",
        "colab_type": "text"
      },
      "source": [
        "## EXERCISE IN CLASS: Use the ETL pipeline into the Keras\n",
        "\n",
        "UUID - #S5E2\n",
        "\n",
        "Just a hint: `input_shape=X_train.shape[1:]`\n",
        "\n",
        "But you need to tell me why :) \n",
        "\n",
        "Build a network that predicts house prices using the ETL you just created. How does it perform? Try to visualize the network in TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_v61CDmkw0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWwBnfqrd4nK",
        "colab_type": "text"
      },
      "source": [
        "# Bonus: extra Dataset functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ai2NBScXbN",
        "colab_type": "text"
      },
      "source": [
        "Here is a short description of each method in the `Dataset` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "99JVwGn5cXbO",
        "colab_type": "code",
        "outputId": "eaab7156-f20c-4675-edce-8f6d09627862",
        "colab": {}
      },
      "source": [
        "for m in dir(tf.data.Dataset):\n",
        "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
        "        func = getattr(tf.data.Dataset, m)\n",
        "        if hasattr(func, \"__doc__\"):\n",
        "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "● apply()              Applies a transformation function to this dataset.\n",
            "● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.\n",
            "● batch()              Combines consecutive elements of this dataset into batches.\n",
            "● cache()              Caches the elements in this dataset.\n",
            "● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
            "● element_spec()       The type specification of an element of this dataset.\n",
            "● enumerate()          Enumerates the elements of this dataset.\n",
            "● filter()             Filters this dataset according to `predicate`.\n",
            "● flat_map()           Maps `map_func` across this dataset and flattens the result.\n",
            "● from_generator()     Creates a `Dataset` whose elements are generated by `generator`.\n",
            "● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.\n",
            "● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.\n",
            "● interleave()         Maps `map_func` across this dataset, and interleaves the results.\n",
            "● list_files()         A dataset of all files matching one or more glob patterns.\n",
            "● map()                Maps `map_func` across the elements of this dataset.\n",
            "● options()            Returns the options for this dataset and its inputs.\n",
            "● padded_batch()       Combines consecutive elements of this dataset into padded batches.\n",
            "● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.\n",
            "● range()              Creates a `Dataset` of a step-separated range of values.\n",
            "● reduce()             Reduces the input dataset to a single element.\n",
            "● repeat()             Repeats this dataset so each original value is seen `count` times.\n",
            "● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
            "● shuffle()            Randomly shuffles the elements of this dataset.\n",
            "● skip()               Creates a `Dataset` that skips `count` elements from this dataset.\n",
            "● take()               Creates a `Dataset` with at most `count` elements from this dataset.\n",
            "● unbatch()            Splits elements of a dataset into multiple elements.\n",
            "● window()             Combines (nests of) input elements into a dataset of (nests of) windows.\n",
            "● with_options()       Returns a new `tf.data.Dataset` with the given options set.\n",
            "● zip()                Creates a `Dataset` by zipping together the given datasets.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
